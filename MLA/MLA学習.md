# MLA 学習

機械学習における「推論」とは、事前に大量のデータを用いて学習（トレーニング）されたモデルに対して、新しい入力データを与え、その結果（分類、予測、回帰など）を出力するプロセスを指します。つまり、モデルが「学習」で獲得した知識を実際の問題解決に適用する段階のことです。

### 学習と推論の違い

- 学習（トレーニング）  
  大量のラベル付き（またはラベルなし）のデータを使って、モデルがパターンや特徴を自動的に抽出し、パラメーターを調整する過程です。例えば、猫と犬の画像を多数読み込ませ、各カテゴリの特徴を捉えることを学習します。

- 推論（インファレンス）  
  学習済みモデルに対して、新しい（未見の）データを入力し、学習したパターンや特徴に基づいて結果を出力する工程です。たとえば、未知の画像に対して「猫」か「犬」かを判断する処理が推論にあたります。

このように、推論は実際の運用環境でモデルが利用される際の動作となり、学習によって得られた知識を現実のデータに適用して答えを導く非常に重要なステップです。

例えば、自動運転車では、カメラやセンサーからの映像データを推論によって解析し、歩行者や障害物の存在を認識して安全な走行経路を決定します。また、チャットボットや大規模言語モデル（LLM）では、ユーザーからの問い合わせに対して適切な回答を生成するために推論が利用されています。

このように、推論は機械学習システムの実際の活用段階であり、学習フェーズで得たモデルを現実のデータに対して適用し、意味のある出力や予測を行うプロセスなのです

![20250131144107](https://github.com/user-attachments/assets/e2a21739-dc4e-4e8e-a1a8-3eefacb8147e)

- Amazon Rekognition の機能全体像
  - 有名⼈認識
  - 顔検索
  - ⼈物の動線追跡
  - 顔検出・分析
  - 動画ストリーミングの分析
  - コンテンツの テキストの検出 モデレーション
  - 物体・シーン検出
  - 保護具検知 動画のシーン分析
  - カスタムラベル Face Liveness

<img width="1277" alt="image" src="https://github.com/user-attachments/assets/df2a0d54-2b5d-42b6-9047-2ee73efe4718" />

以下は、Amazon SageMaker のトレーニングジョブ、エンドポイント、Ground Truth、そして Model Monitor の基本的なアーキテクチャと処理フローの全体像です。全体の流れとしては、まずトレーニングジョブでモデルを作成し、そのモデルをエンドポイントにデプロイ。エンドポイントでは推論リクエスト／レスポンスをキャプチャし、さらに正解データ（Ground Truth）を別途用意して、両者をマージして分析を行い、CloudWatch にメトリクスを送信しアラームを発する仕組みとなっています。

---

### 1. トレーニングフェーズ – SageMaker Training Job

- データ準備とラベリング  
  トレーニング用のデータセットには、各サンプルに対する正解ラベル（Ground Truth）が含まれています。たとえば、画像分類タスクなら各画像に「猫」「犬」などの正解ラベルが付与されます【citeturn1search9】。

- トレーニングジョブの実行  
  SageMaker Training Job を利用して、上記データセットをもとに ML モデルを学習させます。ジョブの結果として、学習済みのモデル（モデルアーティファクト）が Amazon S3 に保存され、またトレーニング時のパフォーマンス（精度や F1 スコアなど）を計測し、これをベースラインとして後続の監視で利用します【citeturn1search8】。

---

### 2. デプロイフェーズ – SageMaker エンドポイントとデータキャプチャ

- モデルのデプロイ  
  学習済みモデルを SageMaker Endpoint にデプロイします。これにより、リアルタイムの推論リクエストに対応できる REST API エンドポイントが構築されます。

- データキャプチャ機能の有効化  
  エンドポイントにデータキャプチャ機能を設定すると、各推論リクエストとそのレスポンス（および付随するメタデータ）が自動的に Amazon S3 に保存されます。これらは後でモデルの評価に利用されます【citeturn1search0】。

---

### 3. Ground Truth の準備とマージ

- Ground Truth の用意  
  本番環境での評価用に、実際の正解データ（Ground Truth）を用意します。たとえば、顧客の離反予測の場合、実際に離反したかどうかという情報が Ground Truth となります。これらの正解データは SageMaker Ground Truth サービスなどを用いて作成することも可能です【citeturn1search15】。

- マージジョブ  
  定期的なジョブ（または Model Monitor 内部のマージ処理）で、S3 に保存された推論キャプチャデータと Ground Truth データが、共通のユニーク識別子（inferenceId や eventId）を用いて結合（マージ）されます。これにより、各推論結果に対する正解ラベルが付与され、正確な評価が可能となります【citeturn1search0】。

---

### 4. モニタリングと分析フェーズ – SageMaker Model Monitor

- モニタリングジョブの実行  
  定期的にスケジュールされたモニタリングジョブが、マージされたデータを対象に実行されます。ここでは、トレーニング時に設定したベースライン（モデル品質の指標）と、現状の推論結果および Ground Truth を比較して、モデルの品質やバイアスのドリフト（概念ドリフト）を検出します。

- 評価結果の出力とアラーム  
  分析結果はレポートとして Amazon S3 に出力され、さらに CloudWatch に評価結果のメトリクスが送信されます。CloudWatch で設定した閾値を超える場合、アラームが発報されるため、運用担当者は問題発生時に迅速に対応することが可能となります【citeturn1search8】。

---

### まとめ：全体の処理フロー

1. トレーニングジョブでモデル学習  
   → トレーニングデータ（正解ラベル付き Ground Truth を含む）を用いてモデルを作成し、ベースライン指標を確立。

2. エンドポイントへのデプロイとデータキャプチャ  
   → 学習済みモデルをエンドポイントにデプロイし、推論リクエスト／レスポンスを S3 に保存。

3. Ground Truth の提供とマージ  
   → 本番環境で収集された正解データ（Ground Truth）を別途アップロードし、キャプチャデータとユニーク識別子でマージ。

4. モニタリングジョブによる分析  
   → マージ済みデータをもとに、モデル品質やバイアスの評価を実施し、ベースラインと比較して結果を算出。

5. CloudWatch による監視とアラーム  
   → 分析結果のメトリクスが CloudWatch に送信され、閾値超過時にアラームを発することで、異常を早期検知。

このように、SageMaker のトレーニングジョブで学習したモデルをエンドポイントにデプロイし、推論キャプチャと Ground Truth を組み合わせて定期的に評価・分析する仕組みにより、本番環境でのモデルの健全性や精度の維持が実現されます【citeturn1search0】【citeturn1search13】.

- 準備: インフラ環境,データの収集＆準備
  - SageMaker Ground Truth:
    - SageMaker Model Monitor の共通機能のひとつに、「モデル精度を Ground Truth と推論結果で比較する」というものがあります。ここでの「Ground Truth（グラウンドトゥルース）」とは、各入力データに対して「本当の正解」や「正確なラベル」として事前に用意されたデータのことを指します。
    - 具体的には、たとえば画像分類タスクの場合、各画像に対して「猫」や「犬」といった正しいラベルが付けられているデータ（＝グラウンドトゥルース）を用意しておきます。モデルが新たな画像に対して予測（推論）を行ったとき、その予測結果とグラウンドトゥルース（正解ラベル）を比較することで、モデルの精度やパフォーマンスがどれだけ維持されているかを評価できるのです。
    - この比較により、もしモデルが時間の経過とともに精度が低下している（いわゆるコンセプトドリフトが発生している）場合や、データの質に問題がある場合にはアラートを発生させ、必要な再トレーニングやシステムの見直しといった対策を講じることが可能になります.
    - 要するに、Ground Truth は「正解データ」として、モデルの予測結果（推論結果）が実際にどれだけ正しいかを検証するための基準となるデータなのです。
  - SageMaker Data Wrangler
  - SageMaker Clarify:機械学習モデルのバイアスを検出、モデル予測を理解
  - SageMaker Feature Store
    - 特徴量をセキュアに保存、探す、共有
  - Glue DataBrew: ETL 処理のデータクレンジングや分析処理はノーコードでデータ探索/クレンジング/加⼯が可能

| サービス名                              | タイプ       | 特徴                                                  | キーワード                               |
| --------------------------------------- | ------------ | ----------------------------------------------------- | ---------------------------------------- |
| Amazon SageMaker Data Wrangler          | バッチ       | 機械学習に特化                                        | SageMaker と連携, ノーコードでデータ変換 |
| AWS Glue DataBrew                       | バッチ       | シンプルなデータ変換                                  | 完全ノーコードでデータ変換               |
| AWS Glue                                | バッチ       | 一般的なデータ変換, 機械学習にも応用可能              | ETL, ビッグデータ                        |
| Amazon EMR                              | バッチ       | 一般的なデータ変換                                    | Hadoop, Hive, Spark                      |
| Amazon Managed Service for Apache Flink | リアルタイム | ストリーミングデータ特化, Python でのカスタマイズ可能 | リアルタイム                             |

- モデル構築: モデルのデザイン＆ 訓練モデルの評価
  - SageMaker Debugger
  - SageMaker Experiments
- デプロイ: 本番環境のモデルから個々の予測を説明する
  - SageMaker Model Resistry
  - SageMaker Neo
  - SageMaker Pipelines
- 運⽤管理: モデルの精度・機能要件のモニタリング
  - SageMaker Model Monitor
  - SageMaker Clarify

## ML におけるデータ処理

### データソースの指定

- Amazon FSx:
  - Lustre、NetApp ONTAP、OpenZFS、Windows ファイルサーバーのフルマネージドサービス
  - いつ使うの︖
    - ⾼性能が要求されるワークロード
    - 要件別でファイルシステムを選択可
  - いつ避けるの︖
    - ⻑期保存が主な⽬的の場合（S3 で⼗分）
    - シンプルなファイル共有のみが必要（EFS で⼗分）
- Amazon FSx for Lustre:
  - Lustre ファイルサーバー⽤のフルマネージドサービス
  - いつ使うの︖
    - ⾼性能コンピューティング(HPC)
    - 複数 GPU インスタンスでの分散学習
    - ⼤規模データセットをホストするのに適している
    - リアルタイムな推論が必要な本番環境
  - いつ避けるの︖
    - NFS や SMB プロトコルに対応していない（独⾃のプロトコルを使⽤）
    - シンプルなファイル共有のみが必要（FSx で共通する事）

| 判断基準                           | Yes の場合           | No の場合                        |
| ---------------------------------- | -------------------- | -------------------------------- |
| コストよりもレイテンシを優先するか | 次の判断へ           | Amazon S3                        |
| より高いパフォーマンス要件         | 次の判断へ           | 次の判断へ                       |
| 機械学習や HPC ワークロード        | FSx for Lustre       | 次の判断へ                       |
| NFS と SMB 両方に対応が必要か      | FSx for NetApp ONTAP | 次の判断へ                       |
| プロトコル選択                     | NFS: FSx for OpenZFS | SMB: FSx for Windows File Server |

注記：

- NFS: UNIX ベースのファイル共有プロトコル
- SMB: Windows OS のファイル共有プロトコル

### データ変換

- カテゴリ値のエンコーディング（One-Hot エンコーディング）
  - 概要: One-Hot エンコーディングは、カテゴリカルデータを数値データに変換する手法です。
  - 仕組み
    - 各カテゴリを別々の列として表現
    - 該当するカテゴリには 1 を設定
    - その他のカテゴリには 0 を設定
  - 注意点
    - カテゴリの数が多い場合、データセットのサイズが大きく膨らむ可能性がある
    - これは「次元の呪い」につながる可能性があり、モデルのパフォーマンスに影響を与える可能性がある
  - 例：血液型のエンコーディング

| A 型 | B 型 | O 型 | AB 型 |
| ---- | ---- | ---- | ----- |
| 1    | 0    | 0    | 0     |
| 0    | 1    | 0    | 0     |
| 0    | 0    | 1    | 0     |
| 0    | 0    | 0    | 1     |

- カテゴリ値のエンコーディング（ラベルエンコーディング）
  - ラベルエンコーディングとは、カテゴリ値を数値に変換し、それぞれに整数を割り当てる手法です。
  - 特に順序や序列があるデータに適しています。
  - 特徴：
    - シンプルな数値変換
    - メモリ効率が良い
    - 順序性のあるデータに最適
    - One-Hot エンコーディングと比べてデータ量を抑えられる
  - 注意点：
    - 数値間の大小関係が生まれるため、順序性のないカテゴリデータには適さない場合がある
    - 機械学習モデルが数値の順序関係を重要な特徴として扱う可能性がある
  - 例：衣服のサイズ変換

| サイズ | エンコード後の値 |
| ------ | ---------------- |
| S      | 0                |
| M      | 1                |
| L      | 2                |

- 特徴量
  - 特徴量とは予測の⼿掛かりとなる変数のこと
  - 機械学習モデルが予測を⾏うためにトレーニングおよび推論中に使⽤する⼊⼒値
  - 天気を予測する場合
    - 時間情報︓⽇付、時刻
    - 地理情報︓緯度、経度、標⾼
    - 気象データ︓気温、湿度、気圧
  - 売り上げを予測する場合
    - 時間情報︓⽇付、時刻
    - 来客データ︓⼈数、性別、年齢層
    - 商品データ︓値段、発売⽇
- 数値特徴量エンジニアリング
  - スケーリング: すべての値が特定の範囲になるように数値を変換
    - 正規化: データポイントとデータセットの最低値の差分をデータレンジと割って求めます。外れ値があると、正規化⼿法が効果的に機能しなくなる可能性があります。
    - 標準化: データにおける平均値（𝝁 ）を０、標準偏差（𝝈）を１にする⼿法
      - 平均値とデータポイントとの差分を標準偏差と割って求めます
      - 正規化の場合ほど外れ値がマイナスの要因になりません
    - ビニング: 数値特徴量を少数のビン、つまりカテゴリにグループ化する⼿法
    - 対数変換 log(): 歪んだ数値データを正規化し、外れ値の影響を軽減し、値を正規分布に近づけるために使⽤されます。極端に⼤きな値があるときに有⽤
  - 次元削減: 重要な特徴量のカテゴリのみを残す
    - 主成分分析（PCA）: 次元削減に使⽤できる統計的⼿法。元の特徴量のばらつきをできる限り保持したまま、特徴量の総数を減らして、より効率的に計算できるようにする。

スケーリング（正規化・標準化）の使い分け
| 項目 | 正規化 | 標準化 |
|------|--------|--------|
| 変換する値 | データを 0 から 1 に収める | 平均を 0、標準偏差を 1 |
| 使用タイミング | 最大値と最小値が決まっている | ・データが正規分布に従っている<br>・最小値と最大値が決まっていない |
| 注意点 | ・外れ値に弱い<br>・データの解釈が難しくなる | ・外れ値に弱い<br>・データの解釈が難しくなる |

- テキスト特徴量エンジニアリング:

  - Bag-of-Words モデルでは単語のシーケンスは追跡せず、各観測値の単語数を数えます。
  - N-gram モデルは、n サイズの単語のグループを⽣成することで、Bag-of-Words モデルを発展させたものです。

- お⾦稼ぐ、俺らはスター
- お⾦稼ぐ、私はスター

| ID  | 単語   | 頻度 |
| --- | ------ | ---- |
| 1   | お金   | 2    |
| 2   | 稼ぐ   | 2    |
| 3   | 俺ら   | 1    |
| 5   | スター | 2    |
| 6   | 私は   | 1    |

- 例︓n=2 の場合
- お⾦稼ぐ、俺らはスター
- お⾦稼ぐ、私はスター

| ID  | 単語         | 頻度 |
| --- | ------------ | ---- |
| 1   | お金稼ぐ     | 2    |
| 2   | 稼ぐ、俺らは | 1    |
| 3   | 俺らはスター | 1    |
| 4   | 稼ぐ、私は   | 1    |
| 5   | 私はスター   | 1    |

### データ検証

- バイアスに対しての戦略
  - リサンプリング: サンプルを減らすか増やす
  - Amazon SageMaker Data Wrangler
    - Random undersampler: ランダムに多数派のデータを排除
    - Random oversampler: ランダムに少数派のサンプルを複製
    - SMOTE: 実際の少数派のサンプルから合成データを⽣成
  - データ拡張: 既存のデータから新しいデータを合成、⼈⼯的にデータ量を増加

### 最終ステップ(データ検証、データ分割)

- データ分割（ランダム）:
  - トレーニングセット: 70%
  - 検証セット: 10%, 精度を⾼める
  - テストセット: 20% , 評価をする

## ML モデルの開発

- Amazon Rekognition: 画像認識
- Amazon Transcribe: ⾳声認識 ⾳声をテキストに。Speech - t o - Text
- Amazon Textract: スキャン し た ⽂ 書 ( pdf, png , jpg, …) などの ⾮構造化 データ か ら テキスト や 構造化 データ を 抽 出
- Amazon Comprehend: テキストを理解する上で重要な、エンティティ、キーフレーズ、感情などを検出
- Amazon Polly: ⾳声合成 テキストを⾳声に
- Amazon SageMaker JumpStart: 既存の基盤モデルにアクセスして開発・運⽤をすぐ開始できるハブ
- Amazon SageMaker の組み込みアルゴリズム:

  - ⽤意されたアルゴリズムの中から、問題にあったアルゴリズムを選択して学習
    - ⼀般化線形モデル: 学習時間短い, 解釈可能性⾼い, ツリーベースモデル, 柔軟性は低い
    - ツリーベースモデル: 線形モデルよりも正確, 解釈可能性⾼い, ⾏列分解
    - ニューラルネットワーク: 複雑な関係をモデル化できる, 学習時間⻑い, ⾏列分解, 解釈可能性低い
    - ⾏列分解: 特徴量の中から重要な部分を取り出す
    - クラスタリング: 特徴量を類似性でグルーピング

- 教師あり学習

| 学習タイプ         | サブタイプ | 予測対象 | 例                                           | アルゴリズム |
| ------------------ | ---------- | -------- | -------------------------------------------- | ------------ |
| 分類               | 二項分類   | 離散値   | 病気 or 病気ではない。予測するラベルの数が 2 | 線形学習     |
| 分類               | 多項分類   | 離散値   | 予測するラベルの数が 2 それ以上              | XGBoost, kNN |
| 回帰               | -          | 連続値   | 住宅の価格                                   | 線形学習     |
| レコメンデーション | -          | 好み     | おすすめの映画                               | 因数分解機   |

- 教師なし学習

| 学習タイプ     | 説明                                     | アルゴリズム                                |
| -------------- | ---------------------------------------- | ------------------------------------------- |
| クラスタリング | データを似た特徴を持つグループに分類     | k 平均法,LDA                                |
| 次元削減       | データの特徴量を減らし本質的な情報を抽出 | PCA                                         |
| 異常検出       | 通常とは異なるパターンを検出             | ・ランダムカットフォレスト<br>・IP Insights |

- テキスト・音声

| タイプ   | 用途                                                                                               | アルゴリズム |
| -------- | -------------------------------------------------------------------------------------------------- | ------------ |
| テキスト | 分類                                                                                               | BlazingText  |
| テキスト | 埋め込み（単語・文章）、テキストを数値表現に変換。コンピュータで扱いやすくし、類似度を定量化できる | Object2Vec   |
| テキスト | 機械翻訳                                                                                           | Seq2Seq      |
| テキスト | トピックモデリング。テキストから話題を判断                                                         | LDA, NTM     |
| 音声     | 音声処理                                                                                           | Seq2Seq      |

- 画像または動画・時系列

| タイプ    | 用途               | アルゴリズム                        |
| --------- | ------------------ | ----------------------------------- |
| 画像/動画 | 画像分類           | ResNet                              |
| 画像/動画 | 物体検出           | SSD(VGG/ResNet ベース)              |
| 画像/動画 | セグメンテーション | FCN, PSP, DeepLab v3(ResNet ベース) |
| 時系列    | 予測               | DeepAR                              |

- モデルを効率よく学習するには
  - 学習時間を短くする: 「モデルが複雑」かつ「データが多い」→ 学習時間が⻑くなり、開発サイクルの速度が低下
    - 早期停⽌（Early Stopping）:
      - 学習プロセスを途中で停⽌すること
      - 各エポック後にメトリクスを評価して、過去のエポックと⽐較して以前より悪い値になったらその時点でトレーニングを停⽌
      - オーバーフィッティング（過学習）を抑える⽅法の 1 つ
- オーバーフィッティング（過学習）:

  - 学習データに過剰に適合し、実際のデータを利⽤した予測が不正確になること
  - 特徴: 学習データの誤差は下がるがテストデータの誤差が上がる
  - 対策:
    - ドロップアウト: ニューラルネットワークにおいて特に効果的。各エポック中にニューラルネットワークの各層にあるニューロンをランダムにドロップアウト (ゼロに設定)
    - L1/L2 正則化:
      - モデルが複雑になりすぎないようにペナルティを与える
      - Why︖
        - 過学習の際、モデルのパラメータが極端な値をとる。
      - 何をするの︖以下が⼩さくなるように学習
        - L1 正則化︓モデルのパラメータの絶対値の合計
        - L2 正則化︓モデルのパラメータの⼆乗の合計
    - K 分割交差検証:
      - データ分割の際にデータを K 個の サブセットに分ける
      - 1 個のサブセット ＝ 検証⽤
      - 残り (K−1) 個のサブセット ＝ 学習⽤

- アンダーフィッティング（学習不⾜）

  - 学習が⾜りず、実際のデータを利⽤した予測が不正確になること
  - 対策としては以下のようなものがある
    - 学習量を増やす
    - モデルを複雑にする（変数を増やしてデータの傾向に反応できるようにする）

- ハイパーパラメータ
  - 機械学習モデルのトレーニングを管理するために使⽤する外部設定変数
  - パラメータのチューニングは⼀般的に⼈間が⼿動で調節する
  - モデル構造や機能、パフォーマンスを直接的に制御可能

| ハイパーパラメータ項目 | 概要                                                                                                        |
| ---------------------- | ----------------------------------------------------------------------------------------------------------- |
| 学習率                 | アルゴリズムが推定値を更新する率のこと。⼩さすぎると学習が進まない。 ⼤きすぎると最適解付近を往復してしまう |
| 学習減衰率             | 学習を高速化するために、時間の経過と共に学習率を徐々に低下させていく率のこと                                |
| ミニバッチサイズ       | トレーニングデータのバッチサイズ、トレーニングセットをいくつかのグループに分割する際のサイズのこと          |
| エポック数             | トレーニングデータセット全体をトレーニング中にモデルに学習させた回数                                        |

- ハイパーパラメータのチューニング⼿法
  - グリッド検索
    - 網羅的なアプローチ
    - 考えられるすべての組み合わせについてモデルをトレーニングして評価
    - 良い点: 考えられるすべての組み合わせが確実に調べられる
    - 悪い点: 計算コストが⾼くなる
  - ランダム検索
    - 指定されて回数分だけ、ランダムに組み合わせを選択
    - 良い点: グリッド検索よりも効率的
    - 悪い点: 最適な組み合わせを⾒逃す可能性
  - ベイズ検索
    - 以前に選択したハイパーパラメータのパフォーマンスを使⽤して、後続のどの値が良さそうな結果になる可能性が⾼いかを予測
    - 良い点: ランダム検索よりも速く良さそうな値に辿り着ける
    - 悪い点: 前の値を使⽤するためスケーリングが難しい

### ML モデル評価のメトリクス

- 混同⾏列 (正解率・正確さ︓Accuracy)
  - 全データに占める TP と TN の割合
  - 実際の正解を引き当てる割合であり、⾼いほど性能が良い
- 混同⾏列 (適合率︓Precision)
  - Positive とされたデータのうち TruePositive の割合
  - 値が⼤きいほど、取りこぼしなく正解を拾えていることを意味する
  - カゼの場合
    - ⾒逃しても命に関わる影響はほとんどない
    - ⾵邪ではないのに⾵邪と予測（FP）して、コストがかかる⽅がデメリットが⼤きい
    - False Positive（FP）を減らしたい
    - 適合率を重視
- 混同⾏列 (再現率︓Recall)
  - 全ての Positve のうち、機械学習モデルが Positive と予測した割合
  - 値が⼤きいほど、正確に Positive を拾えていることを意味する
  - ガンの場合
    - ⾒逃すと命に関わる
    - ガンであるのにガンではないと予測（FN）した⽅がデメリットが⼤きい
    - False Negative（FN）を減らしたい
    - 再現率を重視

|                  | 予測: ⽝            | 予測: ⽝じゃない    |
| ---------------- | ------------------- | ------------------- |
| 実際: ⽝         | True Positive (TP)  | False Negative (FN) |
| 実際: ⽝じゃない | False Positive (FP) | True Negative (TN)  |

ドキュメント「メトリクスと検証」にもある Recall と Precision ですが、これらはモデルのパフォーマンスを測定し、運用するために非常に重要となっています。

モデルによる予測品質の判断は、その利用ケース/用途によって重要とすべきメトリクスが異なります。このとき Recall と Precision はトレードオフの関係にあります。

混同行列(Confusion Matrix) 予測：陽性 予測：陰性
実際：陽性 真陽性(TP) 偽陰性(FN)
実際：陰性 偽陽性(FP) 真陰性(TN)
再現率（Recall）: 実際に陽性だったもののうち、モデルが正しく陽性と予測できた割合。
Precision = TP / (TP + FP)：陽性と予測したもの（TP + FP）のうち、実際に陽性だったもの（TP）の割合。
target_recall を高く設定すると、再現率は高まりますが、適合率は低下する可能性があります。つまり、見逃しは減りますが、誤検知が増える可能性があります。
適合率（Precision）: モデルが陽性と予測したもののうち、実際に陽性だった割合。
Recall = TP / (TP + FN)：実際に陽性だったもの（TP + FN）のうち、正しく陽性と予測できたもの（TP）の割合。
target_precision を高く設定すると、適合率は高まりますが、再現率は低下する可能性があります。つまり、誤検知は減りますが、見逃しが増える可能性があります。
これを理解するためにはまず「Recall」から覚えると良いでしょう。AWS のドキュメントには「再現率 (Recall) は、すべての真陽性を見つけるために使用されるため、がんの検査で重要です。」と記載があり、私はこれを脳内イメージの起点としています。

がんのように、もし治療が遅れると「重篤な結果を招く病気」のような場合には、偽陰性のコストは非常に高くなってしまいます。よって多少偽陽性が増えても、見逃しを最小限に抑えることが重要です。

つまり「Recall を最大にすれば見逃しがなくなる」ということです。ただし、Recall を最大にすることは簡単です。何故なら、予測において全て「陽性」と判断してしまえば（検査する人全員を一旦"陽性"判断としてしまえばいい） Recall は勝手に 100% になるからです。

ですがそのようなモデルが実用に耐えるかというと、耐えません。ここで「Accuracy」や「Precision」の値にも目を向けていくことになると私は認識しています。

- F1 スコア

  - 取りこぼしの少なさと判断の正確性のバランスを表す
  - 精度(Precision)と再現率(Recall)の調和平均で計算される

- SageMaker Debugger
  - トレーニング中やデプロイ中に機械学習モデルをモニタリングおよびデバッグできる SageMaker の機能
  - 過剰適合、過少適合、データ品質の問題などの問題を特定
  - 検出された問題に対して⾃動アクションを実⾏するための組み込みルール Amazon EventBridge と AWS Lambda を特定可能
- SageMaker Experiments
  - 機械学習の実験ワークフローを合理化
  - パラメータ、設定、結果を⾃動で追跡

## ML ワークフローのデプロイとオーケストレーション

- SageMaker Model Registry
  - モデルのバージョン管理
  - モデルへのメタデータ (トレーニングメトリクスなど) の関連付け
  - モデルの承認ステータスの管理
  - モデルデプロイの⾃動化
- Amazon SageMaker のデプロイオプション
  - バッチ推論:
    - ⼤規模データのフルマネージドバッチ推論
    - 推論した分だけの課⾦
    - 定期的に⼤規模データが届くユースケース向け
  - ⾮同期推論:
    - ⼤きなペイロード (~ 1GB) 向け
    - 最⼤ 15 分の⻑いタイムアウト時間
    - ⾃動スケーリング
    - CV/NLP ユースケースなど
  - リアルタイム推論
    - 永続的なマイクロサービスを作成
    - ⾼速なレスポンス（ペイロード上限 6 MB）
    - 外部アプリケーションからアクセス可能
    - ⾃動スケーリング
  - サーバーレス推論
    - トラフィックが予測できないユースケースむけ
    - コールドスタートが許容できる

| デプロイオプション | ユースケース                                                                                                                                                                                                                                                                    |
| ------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| バッチ推論         | リクエストごとに推論をモデルに返す必要がない？ YES                                                                                                                                                                                                                              |
| ⾮同期推論         | リクエストごとに推論をモデルに返す必要がない？ NO<br>処理時間やペイロードが⻑い場合やキューでリクエストを管理する必要があるか？ YES                                                                                                                                             |
| サーバーレス推論   | リクエストごとに推論をモデルに返す必要がない？ NO<br>処理時間やペイロードが⻑い場合やキューでリクエストを管理する必要があるか？ NO<br>断続的なトラフィックやトラフィックのない期間がありますか？ YES                                                                            |
| リアルタイム推論   | リクエストごとに推論をモデルに返す必要がない？ NO<br>処理時間やペイロードが⻑い場合やキューでリクエストを管理する必要があるか？ NO<br>断続的なトラフィックやトラフィックのない期間がありますか？ NO<br>持続的なトラフィックがあり、低く安定したレイテンシーが必要であるか？ YES |

以下は、画像の内容を Markdown 形式の表に変換したものです：

| 特性             | リアルタイム推論            | サーバーレス推論                         | 非同期推論                         | バッチ推論                                   |
| ---------------- | --------------------------- | ---------------------------------------- | ---------------------------------- | -------------------------------------------- |
| 実行モード       | 同期                        | 同期                                     | 非同期                             | 非同期                                       |
| 予測レイテンシー | 秒以下                      | 秒以下                                   | 数秒〜数分                         | 不定                                         |
| 実行頻度         | 可変                        | 可変                                     | 可変                               | 可変 / 固定                                  |
| 呼び出しモード   | 連続ストリーム / API コール | 連続ストリーム / API コール              | イベントベース                     | イベント / スケジュールベース                |
| 推論データサイズ | 小 (< 6MB)                  | 小 (< 6MB)                               | 中 (< 1GB)                         | 大 (> 1GB)                                   |
| ユースケース     | 商品レコメンドなど          | ドキュメントからのデータの抽出や分析など | コンピュータビジョン、物体検知など | NLP など、データサイズや推論時間が長いケース |

- Amazon SageMaker Neo

  - モデルを様々なハードウェア/ソフトウェアでの推論環境に最適化
  - ⾃⾝のモデルを⾼速かつリソースやメモリを効率よくデプロイ可能

- モデル展開戦略まとめ
- All at once:
  - １回のステップで移⾏
  - 移⾏が短時間で完了し、システムの切り替えが簡単
  - 万が⼀失敗すると、システム全体に影響が及ぶ
- Canary:
  - ２回のステップ(⼀部 → 残り)で移⾏
  - 問題が発⽣しても影響範囲が⼩さくリスクが低いが、トラフィック移⾏の柔軟性は低い
- Linear:
  - n 回のステップ(10%〜50%)でトラフィック
  - トラフィック移⾏の柔軟性が⾼いが、移⾏完了までに時間がかかる
- Rolling(In-Place):
  - インスタンス単位で段階的に移⾏
  - インスタンス単位で段階的移⾏するため、リソースの容量が少なくて済む
  - インスタンス単位でクリーンアップを⾏うため、ロールバックが困難

## ML モデルのモニタリング

- データドリフト: 機械学習モデルの学習に使⽤したデータセットと、実際の運⽤環境で扱うデータセットの間に統計的性質の乖離が⽣じる現象のこと
- モデルバイアス: モデルが特定のグループや特性に対して不公平な予測を⾏う傾向のこと
- SageMaker Model Monitor
  - モデルのデプロイ: SageMaker エンドポイントでデータキャプチャを有効化
  - モニタリングジョブの計画: データの質、モデルの精度、バイアス、説明可能性のドリフトを検出および監視
  - ベースライン⽣成: 統計と制約
  - 実際の結果を収集する: このときの Ground Truth をモデルからの予測と統合
  - ドリフト監視結果の表⽰: S3 のレポート,Studio でのメトリクスの可視化,ノートブックでの分析
  - CloudWatch アラート: モデルの再トレーニングデータの更新
- Amazon SageMaker Clarify

  - データの不均衡を特定: データ準備中にバイアスを検出する
  - トレーニングしたモデルのバイアスを確認: モデルにさまざまなタイプのバイアスがどの程度存在するかを評価する
  - モデルの全体的な挙動を説明: モデルの挙動に対する各特徴の相対的重要性を理解する
  - 個々の予測を説明: 個々の推論に対する各特徴の相対的重要性を理解する
  - バイアスとモデルの挙動のドリフトを検出: 変化する現実の条件によるドリフトを検出しアラートを提供する
  - ⾃動⽣成レポート: バイアスに関するレポートや説明を作成し内部プレゼンテーションをサポートする

- モデルのテスト戦略

| 特性             | シャドウテスト                                                   | A/B テスト                                                                       |
| ---------------- | ---------------------------------------------------------------- | -------------------------------------------------------------------------------- |
| 方法             | 新しいモデルの出力を既存モデルと並行してユーザには見せず比較する | 本番環境でユーザーをグループに分けて異なるバリアント（バージョン）のモデルを提供 |
| ユーザーへの影響 | なし                                                             | 異なる品質の出力が提供される                                                     |
| コスト           | 既存インフラのみで実施可能                                       | ユーザー群ごとにトラフィックを分けるため、インフラリソースや運用コストが増加     |

- Amazon Sagemaker Inference Recommender

  - ⾃分がデプロイしたいモデルに最適なインスタンスをサジェスト
  - コストとパフォーマンスのバランスが取れるインスタンスを⾃動で判定

- ROC 曲線
  - 閾値を変更した際の真陽性率と偽陽性率をプロットした曲線
  - オレンジの曲線は閾値を下げるとすぐに真陽性率が⾼まり、なかなか偽陽性率が上がらない
  - ⻘い曲線は偽陽性率の伸びが早く、真陽性率の増加が鈍い
- AUC

  - 曲線より下の⾯積（AUC︓Area Under the Curve）が⼤きいモデルが正確でかつ取りこぼしも少ない良いモデルと⾔える

- Amazon Comprehend

  - ユーザーとのやり取りから個人情報を検出し、再編集するために使用できます。Amazon Comprehend は、英語またはスペイン語のテキスト文書内の PII エンティティを検索し、再編集する機能を提供します。Amazon Comprehend を活用することで、顧客データプラットフォーム内の個人情報を簡単に処理し、匿名化することができます。

- Amazon Fraud Detector
  - 不正行為を検知するためのフルマネージドサービスです。不正行為の例としては、不正取引や偽アカウントの作成などが挙げられます。このソリューションはフルマネージドで、不正検出モデルの構築やカスタマイズが可能です。ただし、独自に構築した既存のモデルをインポートすることはできません。
- SageMaker Experiments
  - SageMaker Studio の機能で、データ、アルゴリズム、パラメータのさまざまな組み合わせを使用して ML 実験を自動的に作成するために使用できます。モデルの再トレーニングのために新しいデータを収集するために SageMaker Experiments を使用することはできません。
- SageMaker Model Monitor
  - 使用すると、モデルの品質を効果的に測定できます。データキャプチャは SageMaker エンドポイントの機能です。データキャプチャを使用してデータを記録し、トレーニング、デバッグ、およびモニタリングに使用できます。その後、データキャプチャによってキャプチャされた新しいデータを使用して、モデルを再トレーニングすることができます。Data Capture は、本番トラフィックに影響を与えることなく、非同期で実行されます。
