# CloudTech Study

## 51.

### まず何がしたいのか？

ある企業が「畑の雑草を予測する機械学習モデル」を作っている。  
つまり、ドローンやセンサーのデータを使って「ここに雑草がある！」と予測したい。

でも、問題がある！  
間違って「雑草あり」と判定すること（偽陽性）を減らしたい。

じゃあ、どうすればいいの？ → 「target_precision を増やす」 が正解！

---

### 用語をわかりやすく解説

エポック（Epoch） って何？  
モデルがデータを 1 回学習することを「1 エポック」と言う。  
エポックを増やすと学習回数が増える（でもやりすぎると過学習になる）。

予測子タイプ（predictor_type） って何？  
モデルが「何を予測するか」の設定。

- multiclass_classifier → 3 つ以上のクラス（例：「雑草 A」「雑草 B」「雑草なし」）を分類する。
- 回帰（regression） → 連続値（例：「雑草の密度」）を予測する。

線形学習（Linear Learner） って何？  
SageMaker にある簡単な機械学習モデル。  
直線的なルールを学習して、データを分類したり数値を予測したりする。

偽陽性（False Positive） って何？  
本当は「雑草なし」なのに、「雑草あり」と間違って判定すること。  
実際には雑草がないのに除草剤をまくと、無駄になる。

---

### なんで「target_precision を増やす」が正解？

precision（適合率） ＝ 「雑草ありと予測したもののうち、本当に雑草があった割合」

\[
\text{Precision} = \frac{\text{正しく雑草ありと予測した数（TP）}}{\text{雑草ありと予測した数（TP + FP）}}
\]

precision を上げると、モデルが「雑草あり」と予測するとき、より慎重になる。  
つまり、「雑草なし」を間違えて「雑草あり」とする（偽陽性）が減る！

だから、偽陽性を減らしたいなら「target_precision」を増やすのが正解！

---

### 他の選択肢はなぜ間違い？

「ウェイト減衰（weight decay）をゼロにする」 → ウェイト減衰は「モデルの複雑さを抑える」ための仕組みで、偽陽性とは関係ない。ゼロにすると、モデルが過学習しやすくなる可能性がある。

「エポック数を増やす」 → エポックを増やすと学習は進むけど、偽陽性が減る保証はない。むしろ、過学習してしまうと、新しいデータに弱くなる可能性もある。

「predictor_type を回帰に変更する」 → 回帰（regression）は「数値の予測」に使う（例：「雑草の面積を予測する」）。今回の問題は「雑草あり or なし or 種類」を分類するので、回帰ではダメ！

### ハイパーパラメータとは？

ハイパーパラメータ（Hyperparameter）は、モデルの学習を始める前に決める設定 のこと。

例えば、料理をするときに「調味料の量（塩・砂糖・醤油の分量）」を決めるのと同じように、  
機械学習のモデルにも「どういう条件で学習させるか？」を設定する項目がある。  
この「事前に決める設定」が ハイパーパラメータ ！

---

### ハイパーパラメータの例

代表的なハイパーパラメータをいくつか紹介するね。

#### 1. 学習率（learning_rate）

学習の進むスピードを決める。

- 学習率が大きい → 早く学習するが、最適な答えを飛ばしやすい（ブレる）
- 学習率が小さい → ゆっくり学習するが、収束まで時間がかかる

📌 例：「ランニングのペース」みたいなもの！速すぎると疲れてしまうし、遅すぎると時間がかかる。

---

#### 2. エポック数（epoch）

データを何回繰り返して学習するか。

- エポックが多い → しっかり学習できるが、過学習のリスクもある
- エポックが少ない → 学習が足りず、精度が低くなる可能性がある

📌 例：「試験勉強の復習回数」みたいなもの！繰り返せば覚えるけど、やりすぎると暗記になってしまう。

---

#### 3. 決定木の深さ（max_depth）（XGBoost など）

決定木モデルがどれだけ細かくルールを作れるかを決める。

- max_depth が大きい → 細かいルールを学べるが、過学習のリスクがある
- max_depth が小さい → シンプルなルールになるが、学習が不十分なこともある

📌 例：「試験の勉強ノート」みたいなもの！細かく書きすぎるとテストと違う問題に弱くなる。

---

#### 4. 予測子タイプ（predictor_type）（Linear Learner の場合）

モデルが 「分類」なのか「回帰」なのか を決める。

- binary_classifier → 2 つのクラス（例：「病気あり or なし」）
- multiclass_classifier → 3 つ以上のクラス（例：「雑草なし / 雑草 A / 雑草 B」）
- regressor → 数値を予測（例：「雑草の密度を%で予測」）

📌 例：「スポーツのルール」みたいなもの！サッカーと野球ではルールが違うから、最初にどの競技をするか決める必要がある。

---

### ハイパーパラメータとパラメータの違い

- ハイパーパラメータ → 学習前に決める設定（人間が調整する）
- パラメータ → 学習後に決まる値（モデルが自分で学習する）

📌 例：「料理のレシピ」と「実際の味」の違い！

- ハイパーパラメータ = 最初に決める「調味料の量」
- パラメータ = 実際に料理を作った後の「味のバランス」

---

### 今回の問題に関係するハイパーパラメータ

- target_precision → Precision（適合率）を上げるための設定
  - 値を増やすと、偽陽性を減らせる！（今回の正解）
- predictor_type → `multiclass_classifier` を選択（「雑草 A / 雑草 B / なし」の 3 クラス分類）

---

### まとめ

- ハイパーパラメータ = 機械学習の「事前に決める設定」
- 代表的なもの → 学習率（learning_rate）、エポック数（epoch）、max_depth など
- 今回の問題では `target_precision` を増やすことで偽陽性を減らせる！

---


## 53.

### 温度パラメータ（Temperature）とは？

温度パラメータ（Temperature） は、LLM（大規模言語モデル）の回答のランダムさを調整するパラメータ です。

- 温度が高い（例：1.0 以上） → よりランダムな回答が生成され、創造的な答えが増える
- 温度が低い（例：0.1） → モデルの出力が決まりやすくなり、一貫性のある回答になる

📌 例：AI に「今日の天気を教えて」と聞いたとき

- 温度が高い（1.0） → 「晴れでしょう！でも、午後は曇るかも。雨が降る可能性もゼロではないですね。」
- 温度が低い（0.1） → 「晴れです。」

温度を下げると、より決まった答えが返りやすくなる！

---

### top_k パラメータとは？

top_k は、LLM が次の単語を決めるときに 「候補の中から何個の選択肢を考慮するか」 を決めるパラメータ。

- top_k が大きい（例：50） → 候補の中から多くの単語を考慮し、よりバリエーションのある回答になる
- top_k が小さい（例：5） → 上位 5 つの候補だけを考慮し、より決まった答えになりやすい

📌 例：「私は〇〇が好きです。」の〇〇を AI が予測するとき

- top_k = 50 → 「ラーメン、カレー、パスタ、寿司、チョコレート…（たくさんの候補から選ぶ）」
- top_k = 5 → 「ラーメン、カレー、パスタ、寿司、うどん（5 つの選択肢から選ぶ）」

top_k を減らすと、ランダム性が減って、一貫性が増す！

---

### 今回の問題のポイント

- モデルの回答を 一貫性のあるものにしたい（同じ質問に対して、毎回似たような答えを返してほしい）。
- 温度を下げる → ランダムな変化を抑え、一貫した回答になる。
- top_k を減らす → 選択肢を制限し、より決まりやすい回答になる。
- この 2 つを組み合わせると、安定した答えが得られる！

## 54.

### ハイパーパラメータチューニングとは？

ハイパーパラメータチューニングとは、機械学習モデルのハイパーパラメータ（学習率、バッチサイズなど）を最適な値に調整する作業 のこと。  
適切なハイパーパラメータを選ぶことで、モデルの精度を最大化し、損失関数（エラー）を最小化できる。

---

### この問題のポイント

- 「検証データセットの損失関数を最小化する」 → より良いモデルを作るために、ハイパーパラメータを最適化する必要がある。
- 「計算時間を最短にする」 → できるだけ素早く最適なハイパーパラメータを見つける方法を選ぶ。

---

### 各ハイパーパラメータチューニング手法の特徴

#### 1. グリッドサーチ（Grid Search） ❌

- 全てのパラメータの組み合わせを試す方法。
- メリット：確実に最適解を見つける可能性が高い。
- デメリット：組み合わせが多いと計算時間がめちゃくちゃ長くなる。

📌 例：「カレーのレシピを決める」  
→ すべての調味料の組み合わせ（塩の量、スパイスの種類、煮込む時間など）を試して、一番おいしいレシピを探す。  
→ でも、全パターン試すので時間がかかりすぎる！

---

#### 2. ランダムサーチ（Random Search） ❌

- 指定した範囲の中からランダムにハイパーパラメータを選ぶ方法。
- メリット：グリッドサーチよりも速い（全ての組み合わせを試さなくてよい）。
- デメリット：完全にランダムなので、最適なハイパーパラメータを見つける効率が悪い。

📌 例：「カレーのレシピを決める」  
→ 適当にスパイスや調味料を組み合わせて試す。  
→ 運が良ければ良いレシピが見つかるけど、無駄な試行が多い！

---

#### 3. ベイズ最適化（Bayesian Optimization） ❌

- 過去の試行結果を活かして、次に試すべきハイパーパラメータを効率よく選ぶ方法。
- メリット：グリッドサーチやランダムサーチよりも効率が良い（無駄な試行を減らせる）。
- デメリット：計算コストが高く、大規模なデータセットでは時間がかかることがある。

📌 例：「カレーのレシピを決める」  
→ まず何種類か試して、それを元に「この組み合わせが良さそう」と予測しながら試す。  
→ 効率はいいけど、大量のデータがあると時間がかかる！

---

#### 4. ハイパーバンド（Hyperband） ✅ （正解！）

- 計算時間を短縮しながら、最適なハイパーパラメータを見つける方法。
- 特徴：途中で性能の悪い試行を早めに打ち切り、リソースを有効活用する。
- メリット：無駄な計算を減らし、大規模データセットでも高速にチューニングできる。

📌 例：「カレーのレシピを決める」  
→ まずいくつかのレシピを同時に試し、ダメそうなものはすぐにやめる。  
→ 良さそうなレシピに集中して、効率よくベストな組み合わせを見つける！

---

### なぜ「Hyperband」が最適なのか？

1. 計算時間を最短にしたい → 途中でダメなパラメータを捨てるので、無駄な計算を減らせる！
2. 大量のデータがある → グリッドサーチやベイズ最適化は計算コストが高くなりすぎる！
3. 無駄な試行を減らして効率よく最適なパラメータを探せる！

---

### まとめ

- ハイパーパラメータチューニングは、最適なパラメータを見つける作業。
- 計算時間を短くするなら「Hyperband」が最適！
- グリッドサーチやランダムサーチは時間がかかりすぎる。
- ベイズ最適化も良いが、計算コストが高いため、Hyperband の方が速い。

## 59.

- 正解は「ロジスティック回帰」です。
  - ロジスティック回帰は、分類問題に適しており、特にバイナリ分類のケースでは標準的なアプローチです。
  - この企業のケースでは、顧客が長期的なサポートを必要とするかどうかを「はい」または「いいえ」で表すため、ロジスティック回帰が最も適しています。
- 「異常検知」は不正解です。
  - 異常検知は通常、データセット内での異常なパターンを特定するために使用されます。
  - この企業の目標は、新規顧客がサポートを必要とするかどうかを予測することであり、異常検知は適切ではありません。
- 「線形回帰」は不正解です。
  - 線形回帰は連続値の予測に使用されるものであり、分類タスクには不適切です。
  - この問題では、バイナリ分類が求められるため、線形回帰は適用できません。
- 「セマンティックセグメンテーション」は不正解です。
  - セマンティックセグメンテーションは主に画像データの分類や領域分割に使用される技術です。
  - この企業のタスクには無関係です
- 解説まとめこの企業の課題はバイナリ分類問題であり、ロジスティック回帰が適切な選択肢です。
  - ロジスティック回帰は、新規顧客がサポートを必要とするかを予測するためのシンプルかつ効果的な手法です。

## 60.

- 正解は「Amazon FSx for Lustre ファイルシステムを作成する。ファイルシステムを既存の S3 バケットにリンクする。トレーニングジョブを調整してファイルシステムから読み取るようにする」です。
  - FSx for Lustre は、高性能で低レイテンシなファイルシステムを提供し、S3 バケットとシームレスに統合できます。
  - この統合により、トレーニングデータを効率的にストリーミングし、大量のファイルを迅速に処理できます。
  - その結果、トレーニングのパフォーマンスが向上します。
- 「S3 Express One Zone ストレージを提供する新しい S3 バケットにデータを転送する。トレーニングジョブを調整して新しい S3 バケットを使用する」は不正解です。
  - S3 Express One Zone はコストを削減しますが、トレーニングパフォーマンスの向上にはつながりません。
  - また、冗長性が低いため、データ耐久性の観点でもリスクがあります。
- 「Amazon Elastic File System (Amazon EFS) ファイルシステムを作成します。既存のデータをファイルシステムに転送します。 トレーニングジョブを調整して、ファイルシステムから読み込みます」は不正解です。
  - EFS は共有ストレージとして適切ですが、大量のデータを高速に処理する性能は FSx for Lustre に劣ります。
  - トレーニングのパフォーマンス向上を求める要件には適していません。
- 「Amazon ElastiCache (Redis OSS) クラスターを作成します。 Redis OSS クラスターを既存の S3 バケットにリンクします。 Redis OSS クラスターからトレーニングジョブに直接データをストリームします」は不正解です。
  = ElastiCache はキャッシュとして使用するには適していますが、数百万のファイルを処理する用途には向いておらず、トレーニングデータの効率的な読み取りを実現するソリューションではありません。
