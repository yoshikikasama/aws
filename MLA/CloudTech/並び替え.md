# CloudTech Study

## 1.

1. フィーチャーグループを作成する
   フィーチャーグループは、特徴量を管理するための論理的な構造です。Feature Store に保存する特徴量は、まずフィーチャーグループとして定義する必要があります。
   フィーチャーグループを作成する際に、スキーマ（列の名前とデータ型）やオンライン/オフラインストアの設定を定義します。
   最初にフィーチャーグループを作成する理由は、このグループが特徴量を保存するための枠組みとなるからです。
2. レコードを取り込む
   フィーチャーグループが作成されたら、次にデータを Feature Store に取り込む必要があります。これを「レコードの取り込み」と呼びます。
   レコードの取り込みは、特徴量を実際に Feature Store に保存する工程であり、これによりデータがオンライン/オフラインストアに登録されます。
   このステップでは、モデルのトレーニングや推論に必要なデータを効率的に格納します。
3. ストアにアクセスしてトレーニング用のデータセットを作成する
   データが Feature Store に保存されたら、次にそのデータをトレーニングデータセットとして使用するためにアクセスします。
   オフラインストアに保存された特徴量データをクエリで抽出し、モデルのトレーニングに適したデータセットを構築します。
   このステップを最後に行う理由は、特徴量が正しく保存されていなければデータセットを作成できないためです。
   解答プロセスの妥当性
   この手順は Amazon SageMaker Feature Store の基本的な操作フローに従っています。

フィーチャーグループの作成は、Feature Store を使用する際の最初の必須ステップであり、特徴量の定義と管理の基盤となります。
レコードの取り込みは、モデルで使用する特徴量を Feature Store に保存する工程です。このステップが完了しないと、次の工程に進むことができません。
ストアへのアクセスとデータセット作成は、保存したデータをトレーニングに利用可能な形式に変換する工程です。このステップが最終段階として適切です。

## 2.

4. AWS Glue クローラーを使用してスキーマと使用可能な列を推論する
   AWS Glue クローラーは、S3 に保存されたデータをスキャンし、スキーマ（データの構造）を自動的に推論するツールです。
   データの列にラベルがない場合でも、Glue クローラーは列のデータタイプや構造を分析し、スキーマを構築できます。
   このステップは、後続のデータクリーニングや加工を進めるための基盤を作る重要な工程です。
5. AWS Glue DataBrew を使用してデータクリーニングと特徴量エンジニアリングを実行する
   AWS Glue DataBrew は、ノーコードでデータクリーニングや加工ができるツールであり、欠損値の処理や列の加工、特徴量エンジニアリングに適しています。
   推論されたスキーマを基に、不完全なデータを補完したり、モデルのトレーニングに適した形式に変換したりする作業を行います。
   データクリーニングや特徴量エンジニアリングは、ML モデルの精度に大きな影響を与えるため、非常に重要です。
6. 処理結果のデータを Amazon S3 に保存する
   DataBrew で加工されたデータは、再利用可能な形式で保存する必要があります。
   S3 に保存することで、データは後続の ML モデルトレーニングに利用可能となります。また、他の AWS サービス（SageMaker や Athena など）との連携が容易になります。

## 5.

解説：各特徴量に適用する特徴量エンジニアリングの方法
この問題では、特徴量エンジニアリングの適切な方法を選択し、それぞれの特徴量に適用します。以下に正解とその理由を説明します。

1. 都市（名前）に適用する方法: ワンホットエンコーディング
   解説: 都市名のようなカテゴリデータ（離散値）は、機械学習モデルで直接使用できません。そのため、ワンホットエンコーディングを使用して、カテゴリを数値形式に変換します。
   例: 「東京」「大阪」「名古屋」の 3 つの都市名をそれぞれ [1, 0, 0], [0, 1, 0], [0, 0, 1] のようにエンコードします。
   理由: ワンホットエンコーディングは、カテゴリデータを特徴量として処理する際の一般的な方法であり、都市名のようなデータに最適です。
2. 年数の種類（住宅の種類と建築年）に適用する方法: 特徴量の分割
   解説: 「住宅の種類」と「建築年」は複数の意味を含む特徴量です。これらを別々の特徴量として分割することで、モデルの解釈性や精度を向上させることができます。
   例: 「一戸建て, 2000 年築」というデータを「住宅の種類: 一戸建て」と「建築年: 2000」に分割します。
   理由: 意味が異なる情報を分割することで、モデルがデータをより正確に処理できるようになります。
3. 建物の面積（平方フィートまたは平方メートル）に適用する方法: 対数変換
   解説: 面積のような数値データは、値のスケールが大きい場合があります。このような場合に対数変換を行うと、値の分布を圧縮し、モデルが扱いやすくなります。
   例: 1000 平方フィートのデータを log(1000) に変換します。
   理由: 対数変換は、スケールが大きい特徴量や非対称な分布を持つ数値データに適しており、面積のようなデータに最適です。
   無関係な方法: 標準化分布
   理由: 標準化分布は、データを平均 0、分散 1 にスケーリングする手法です。ただし、この問題では直接使用する必要がないため、無関係な選択肢となります。
   正解のまとめ
   都市（名前） → ワンホットエンコーディング
   年数の種類（住宅の種類と建築年） → 特徴量の分割
   建物の面積（平方フィートまたは平方メートル） → 対数変換
   学習ポイント
   カテゴリデータにはワンホットエンコーディングを使用する。モデルがカテゴリの違いを適切に認識できるようになる。
   複合的な特徴量は分割することで、モデルの性能向上や解釈性の向上につながる。
   数値データには対数変換を適用し、スケールの大きさや分布の偏りを調整する。
   これらを理解しておくことで、試験だけでなく、実務でのデータ前処理にも応用できます。
